{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now can we train the RNN model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, GRU\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements : <br/>Version of TensorFlow : 2.3.1<br/>Version of Keras : 2.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version of TensorFlow : 2.3.1\n",
      "Version of Keras : 2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Version of TensorFlow :\", tf.__version__)\n",
    "print(\"Version of Keras :\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring RNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 2, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 3, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 4, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 5, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_8 (GRU)                  (None, 6, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 7, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 8, 22)             3036      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 22)             0         \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 22)                3036      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 46        \n",
      "=================================================================\n",
      "Total params: 6,118\n",
      "Trainable params: 6,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start, end = 2, 8\n",
    "mod = sys.modules[__name__]\n",
    "tier = \"DIAMOND\"\n",
    "for tl in range(start, end+1):\n",
    "    RNN = load_model(\"RNN Classifiers/{0}/{0}{1}\".format(tier, tl))\n",
    "    setattr(mod, \"RNN{}\".format(tl), RNN)\n",
    "    print(eval(\"RNN{}\".format(tl)).summary()) # check model state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "\n",
      "DIAMOND1 loaded\n",
      "---------------------------------------\n",
      " >> Processing : RNN2 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN3 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN4 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN5 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN6 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN7 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN8 training start\n",
      "---------------------------------------\n",
      "\n",
      "=======================================\n",
      "\n",
      "\n",
      "=======================================\n",
      "\n",
      "DIAMOND2 loaded\n",
      "---------------------------------------\n",
      " >> Processing : RNN2 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN3 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN4 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN5 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN6 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN7 training start\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      " >> Processing : RNN8 training start\n",
      "---------------------------------------\n",
      "\n",
      "=======================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "for numData in range(1, 6):\n",
    "    data = pd.read_pickle(\"./RNN Dataset/{0}/Train/Data/{0}{1}.pkl\".format(tier, numData))\n",
    "    targetVector = pd.read_pickle(\"./RNN Dataset/{0}/Train/Target/{0}{1}.pkl\".format(tier, numData))\n",
    "    # 승률 계산을 위한 타겟벡터 가공\n",
    "    softmaxTargetVector = []\n",
    "    for blueWin in targetVector:\n",
    "        if blueWin == 1:\n",
    "            softmaxTargetVector.append([1, 0])\n",
    "        else:\n",
    "            softmaxTargetVector.append([0, 1])\n",
    "    softmaxTargetVector = np.array(softmaxTargetVector)\n",
    "    print(\"\\n=======================================\")\n",
    "    print(\"{}{} loaded\".format(tier, numData))\n",
    "    for tl in range(start, end+1):\n",
    "        print(\"---------------------------------------\")\n",
    "        print(\" >> Processing : RNN{} training start\".format(tl))\n",
    "        for idx in range(data.shape[0]):\n",
    "            match = data[idx]\n",
    "            endTime = match.shape[0]\n",
    "            if tl <= endTime:\n",
    "                #print(\" >> >> {}th match endTime = {}\".format(idx, endTime))\n",
    "                input_data = match[:tl, :]\n",
    "                input_data = scaler.fit_transform(input_data)\n",
    "                timestamps, input_dim = input_data.shape\n",
    "                input_data = input_data.reshape(1, timestamps, input_dim)\n",
    "                # Make target shape (-1, 2) for train(RNN 모델을 위해.. 이유는 잘 모르겠음)\n",
    "                target = softmaxTargetVector[idx].reshape(-1, 2)\n",
    "                eval(\"RNN{}\".format(tl)).fit(input_data, target, epochs=1, verbose=0)\n",
    "        print(\"---------------------------------------\")\n",
    "    print(\"=======================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DIAMOND10\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND11\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND12\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND13\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND14\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND15\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND16\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND17\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND18\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND19\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND20\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND21\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND22\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND23\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND24\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND25\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND26\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND27\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND28\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND29\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND30\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND31\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND32\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND33\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND34\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND35\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND36\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND37\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND38\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND39\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND40\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND41\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND42\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND43\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND44\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND45\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND46\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND47\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND48\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND49\\assets\n",
      "INFO:tensorflow:Assets written to: DIAMOND50\\assets\n"
     ]
    }
   ],
   "source": [
    "for tl in range(start, end+1):\n",
    "    #with open(\"./RNN Classifiers/{}{}\".format(tier, tl), \"wb\") as f:\n",
    "    eval(\"RNN{}\".format(tl)).save(\"RNN Classifiers/{0}/{0}{1}\".format(tier, tl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
